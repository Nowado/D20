{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install six numpy scipy Pillow matplotlib scikit-image opencv-python imageio Shapely\n",
    "!pip install git+https://github.com/aleju/imgaug\n",
    "!pip install Keras\n",
    "!pip install pypng\n",
    "!pip install imageio\n",
    "!pip install python-resize-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(imgs)=[], .shape=(32,64,64,3)\n",
    "def augment_imgs(images,chance=0.5, horiz_filp=0.5, vertical_flip=0.2,\n",
    "                crop_pad_range=(.0,.1),scale={'x':(.8,1.2),'y':(.8,1.2)},\n",
    "                translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "                rotate=(-45, 45),shear=(-16, 16),order=[0, 1],cval=(0, 255),\n",
    "                mode=ia.ALL,SomeOf=(0,10)):\n",
    "    ia.seed(1)\n",
    "    print('YEHA')\n",
    "    # Example batch of images.\n",
    "    # The array has shape (32, 64, 64, 3) and dtype uint8\n",
    "\n",
    "    # Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
    "    # e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second\n",
    "    # image.\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "    # Define our sequence of augmentation steps that will be applied to every image.\n",
    "    seq = iaa.Sequential(\n",
    "      [\n",
    "          #\n",
    "          # Apply the following augmenters to most images.\n",
    "          #\n",
    "          iaa.Fliplr(horiz_filp), # horizontally flip 50% of all images\n",
    "          iaa.Flipud(vertical_flip), # vertically flip 20% of all images\n",
    "\n",
    "          # crop some of the images by 0-10% of their height/width\n",
    "          sometimes(iaa.CropAndPad(percent=(0, 0.2),\n",
    "                                   pad_mode=[\"constant\", \"edge\"],\n",
    "                                   pad_cval=(0, 128))),\n",
    "          # Apply affine transformations to some of the images\n",
    "          # - scale to 80-120% of image height/width (each axis independently)\n",
    "          # - translate by -20 to +20 relative to height/width (per axis)\n",
    "          # - rotate by -45 to +45 degrees\n",
    "          # - shear by -16 to +16 degrees\n",
    "          # - order: use nearest neighbour or bilinear interpolation (fast)\n",
    "          # - mode: use any available mode to fill newly created pixels\n",
    "          #         see API or scikit-image for which modes are available\n",
    "          # - cval: if the mode is constant, then use a random brightness\n",
    "          #         for the newly created pixels (e.g. sometimes black,\n",
    "          #         sometimes white)\n",
    "          sometimes(iaa.Affine(\n",
    "              scale=scale,\n",
    "              translate_percent=translate_percent,\n",
    "              rotate=rotate,\n",
    "              shear=shear,\n",
    "              order=order,\n",
    "              cval=cval,\n",
    "              mode=mode\n",
    "          )),\n",
    "\n",
    "          #\n",
    "          # Execute 0 to 5 of the following (less important) augmenters per\n",
    "          # image. Don't execute all of them, as that would often be way too\n",
    "          # strong.\n",
    "          #\n",
    "          iaa.SomeOf((SomeOf),\n",
    "              [\n",
    "                  # Convert some images into their superpixel representation,\n",
    "                  # sample between 20 and 200 superpixels per image, but do\n",
    "                  # not replace all superpixels with their average, only\n",
    "                  # some of them (p_replace).\n",
    "                  sometimes(\n",
    "                      iaa.Superpixels(\n",
    "                          p_replace=(0, 1.0),\n",
    "                          n_segments=(20, 200)\n",
    "                      )\n",
    "                  ),\n",
    "\n",
    "                  # Blur each image with varying strength using\n",
    "                  # gaussian blur (sigma between 0 and 3.0),\n",
    "                  # average/uniform blur (kernel size between 2x2 and 7x7)\n",
    "                  # median blur (kernel size between 3x3 and 11x11).\n",
    "                  iaa.OneOf([\n",
    "                      iaa.GaussianBlur((0, 3.0)),\n",
    "                      iaa.AverageBlur(k=(2, 7)),\n",
    "                      iaa.MedianBlur(k=(3, 11)),\n",
    "                  ]),\n",
    "\n",
    "                  # Sharpen each image, overlay the result with the original\n",
    "                  # image using an alpha between 0 (no sharpening) and 1\n",
    "                  # (full sharpening effect).\n",
    "                  iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)),\n",
    "\n",
    "                  # Same as sharpen, but for an embossing effect.\n",
    "                  iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)),\n",
    "\n",
    "                  # Search in some images either for all edges or for\n",
    "                  # directed edges. These edges are then marked in a black\n",
    "                  # and white image and overlayed with the original image\n",
    "                  # using an alpha of 0 to 0.7.\n",
    "                  sometimes(iaa.OneOf([\n",
    "                      iaa.EdgeDetect(alpha=(0, 0.7)),\n",
    "                      iaa.DirectedEdgeDetect(\n",
    "                          alpha=(0, 0.7), direction=(0.0, 1.0)\n",
    "                      ),\n",
    "                  ])),\n",
    "\n",
    "                  # Add gaussian noise to some images.\n",
    "                  # In 50% of these cases, the noise is randomly sampled per\n",
    "                  # channel and pixel.\n",
    "                  # In the other 50% of all cases it is sampled once per\n",
    "                  # pixel (i.e. brightness change).\n",
    "                  iaa.AdditiveGaussianNoise(\n",
    "                      loc=0, scale=(0.0, 0.05*255), per_channel=0.5\n",
    "                  ),\n",
    "\n",
    "                  # Either drop randomly 1 to 10% of all pixels (i.e. set\n",
    "                  # them to black) or drop them on an image with 2-5% percent\n",
    "                  # of the original size, leading to large dropped\n",
    "                  # rectangles.\n",
    "                  iaa.OneOf([\n",
    "                      iaa.Dropout((0.01, 0.1), per_channel=0.5),\n",
    "                      iaa.CoarseDropout(\n",
    "                          (0.03, 0.15), size_percent=(0.02, 0.05),\n",
    "                          per_channel=0.2\n",
    "                      ),\n",
    "                  ]),\n",
    "\n",
    "                  # Invert each image's chanell with 5% probability.\n",
    "                  # This sets each pixel value v to 255-v.\n",
    "                  iaa.Invert(0.05, per_channel=True), # invert color channels\n",
    "\n",
    "                  # Add a value of -10 to 10 to each pixel.\n",
    "                  iaa.Add((-10, 10), per_channel=0.5),\n",
    "\n",
    "                  # Change brightness of images (50-150% of original value).\n",
    "                  iaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
    "\n",
    "                  # Improve or worsen the contrast of images.\n",
    "                  iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5),\n",
    "\n",
    "                  # Convert each image to grayscale and then overlay the\n",
    "                  # result with the original with random alpha. I.e. remove\n",
    "                  # colors with varying strengths.\n",
    "                  iaa.Grayscale(alpha=(0.0, 1.0)),\n",
    "\n",
    "                  # In some images move pixels locally around (with random\n",
    "                  # strengths).\n",
    "                  sometimes(\n",
    "                      iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)\n",
    "                  ),\n",
    "\n",
    "                  # In some images distort local areas with varying strength.\n",
    "                  sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05)))\n",
    "              ],\n",
    "              # do all of the above augmentations in random order\n",
    "              random_order=True\n",
    "          )\n",
    "      ],\n",
    "      # do all of the above augmentations in random order\n",
    "      random_order=True\n",
    "    )\n",
    "\n",
    "    images_aug = seq.augment_images(images)\n",
    "    return images_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_transforms(img,count=50):\n",
    "    return augment_imgs(np.array([img]*count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-9c63747e6ad0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-9c63747e6ad0>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def files2xy(mode=='floyd'):\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def files2xy(mode=='floyd'):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    i=0\n",
    "    cur_dir=os.getcwd()\n",
    "    if mode=='floyd':\n",
    "        os.chdir('/floyd/input/d20')\n",
    "    if mode=='home'\n",
    "        os.chdir('/floyd/input/d20')\n",
    "    files = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "    for f in files:\n",
    "        if f.endswith('jpg'):\n",
    "            print(f)\n",
    "            print(str(i)+' out of about '+str(len(files)))\n",
    "            num_code=f[:-3]\n",
    "            im = Image.open(f)\n",
    "            y.append(num_code[:1])\n",
    "            x.append(list(im.getdata()))\n",
    "            i+=1\n",
    "    os.chdir(cur_dir)\n",
    "    return x,y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=files2xy()\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_count=195\n",
    "labels=y\n",
    "images=x\n",
    "labels=np.array(y)\n",
    "images = np.array([list(t) for ll in images for t in ll])\n",
    "x=np.reshape(images,(pic_count,1024,768,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_base, x_test_base, y_train_base, y_test_base = train_test_split(images,labels)\n",
    "print('x_train shape:', x_train_base.shape)\n",
    "print(x_train_base.shape[0], 'train samples')\n",
    "print(x_test_base.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=20\n",
    "y_test=np.zeros(shape=(y_test_base.shape[0],count))\n",
    "for i in range(y_test_base.shape[0]):\n",
    "    y_test[i,:]=y_test_base[i,]\n",
    "y_test=np.reshape(y_test,(y_test_base.shape[0]*count,))\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "print('ay')\n",
    "for pic in x_train_base:\n",
    "  x_train=x_train+img_to_transforms(pic,count)\n",
    "x_test=[]\n",
    "for pic in x_test_base:\n",
    "  x_train=x_train+img_to_transforms(pic,count)\n",
    "y_train=y_train_base*count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=50\n",
    "x_train=[]\n",
    "for pic in x_train_base:\n",
    "  x_train=x_train+img_to_transforms(pic,count)\n",
    "x_test=[]\n",
    "for pic in x_test_base:\n",
    "  x_train=x_train+img_to_transforms(pic,count)\n",
    "y_train=y_train_base*count\n",
    "y_test=y_test_base*count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
